{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyP4/ThUyiDBTZoH4xMDD3Uf"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VECKzGE_G_ja","executionInfo":{"status":"ok","timestamp":1694836824546,"user_tz":-540,"elapsed":15139,"user":{"displayName":"김동진","userId":"10023974564951004903"}},"outputId":"c2d18098-96c6-499e-ad99-bd1d21cffd8e"},"outputs":[{"output_type":"stream","name":"stdout","text":["  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"]}],"source":["pip install git+https://github.com/openai/whisper.git -q"]},{"cell_type":"code","source":["import whisper\n","model = whisper.load_model(\"base\")\n","model.device"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6nc3G7UgHbAT","executionInfo":{"status":"ok","timestamp":1694836852695,"user_tz":-540,"elapsed":27711,"user":{"displayName":"김동진","userId":"10023974564951004903"}},"outputId":"b24343f5-03a8-4b17-bbf9-8c8f5c82653b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|███████████████████████████████████████| 139M/139M [00:15<00:00, 9.39MiB/s]\n"]},{"output_type":"execute_result","data":{"text/plain":["device(type='cuda', index=0)"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["!git clone https://github.com/petewarden/openai-whisper-webapp"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"opWRVzUWHlBA","executionInfo":{"status":"ok","timestamp":1694836856792,"user_tz":-540,"elapsed":523,"user":{"displayName":"김동진","userId":"10023974564951004903"}},"outputId":"ed21cfdb-9296-42fb-fc0c-0772e2935668"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'openai-whisper-webapp'...\n","remote: Enumerating objects: 33, done.\u001b[K\n","remote: Counting objects: 100% (33/33), done.\u001b[K\n","remote: Compressing objects: 100% (32/32), done.\u001b[K\n","remote: Total 33 (delta 12), reused 5 (delta 1), pack-reused 0\u001b[K\n","Receiving objects: 100% (33/33), 1.40 MiB | 23.81 MiB/s, done.\n","Resolving deltas: 100% (12/12), done.\n"]}]},{"cell_type":"code","source":["def transcribe(audio):\n","\n","  audio = whisper.load_audio(audio)\n","  audio = whisper.pad_or_trim(audio)\n","\n","  mel = whisper.log_mel_spectrogram(audio).to(model.device)\n","  _, probs = model.detect_language(mel)\n","  print(f\"Detected language: {max(probs, key=probs.get)}\")\n","\n","    # decode the audio\n","  options = whisper.DecodingOptions()\n","  result = whisper.decode(model, mel, options)\n","  return result.text\n"],"metadata":{"id":"gkAUAFUmHux4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import time\n","time1 = time.time()\n","easy_text = transcribe(\"/content/openai-whisper-webapp/mary.mp3\")\n","time2 = time.time()\n","\n","print(\"Execution time : \", time2 - time1)\n","print(easy_text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DMwbkHKzKmVx","executionInfo":{"status":"ok","timestamp":1694837290872,"user_tz":-540,"elapsed":933,"user":{"displayName":"김동진","userId":"10023974564951004903"}},"outputId":"8d96aa62-2c20-45ff-852b-ca95c8ffa640"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Detected language: en\n","Execution time :  0.529646635055542\n","Mary had a little lamb, its fleece was white as snow, and everywhere that Mary went, the lamb was sure to go.\n"]}]}]}